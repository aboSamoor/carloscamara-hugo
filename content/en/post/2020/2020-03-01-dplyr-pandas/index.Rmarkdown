---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Manipulating dataframes in R and Python"
subtitle: "Comparing tidyverse and pandas"
summary: ""
authors: ["admin"]
tags: ["R", "Python", "dataframe", "pandas", "tidyverse"]
categories: ["Data Science"]
date: 2020-02-08T17:46:34Z
lastmod: 2020-02-01T17:46:34Z
featured: false
draft: false
math: true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false
  placement: 2

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

While I have been using `R` for many years now (mainly for data manipulation and visualization), and I am extremely happy with some of its features (like how easy is to deal with data or to create interactive reports that can be exported in plenty of different outputs, such as pdf, documents, slides, dashboards or blog posts like this one). However, I have always wanted to learn `python`, mostly because it is a multi-purpose language that I would be able to use in other aspects of my everyday life such as web development, `QGIS` or Academic research. It is for that reason that I have recently started to learn `python`'s `pandas`.

In the following blog post I will be comparing how to perform the same tasks using `pandas` and `tidyverse`. This mainly serves two learning outcomes:

1.  To generate a cheat sheet that can work as a reminder (for myself): I know there are pages like [this one on `pandas` documentation comparing it to `R`'s syntax](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html), but I learn by doing, so I needed to write the code myself)
2.  To use `reticulate` package, which allows running both, `R` and `python` within the same document (a `Rmarkdown` file to be more specific)

## Loading environment

Since I want to use `Python` and `R` from a `.Rmarkdown` file, I first need to load `reticulate` for this, which is a `python` interface for `R`. Also, since `pandas` is not a standard library module, I need to load a python environment[^1] with the required packages. `reticulate` makes it possible to load environments created with `anaconda`.

[^1]: If there is something that I have fallen in love with `python` so far is how convenient and easy are to create virtual environments from a simple `yaml` file listing all the dependencies. This is something that would be very useful in `R`, too and I should explore in the future: I know `packrat` is there for this purpose, but it is not as fast and easy to deal with as `conda` environments. On the other hand, if I am not mistaken, `conda` also has `R` libraries, so it may be possible to create conda environments for R, too.

The last step is to load some data about COVID-19 provided by `coronavirus` package, which I will be using in this blog post.

```{r}
library(reticulate)
library(DT)
use_condaenv('osm_imports_preparations', required = TRUE)


```

## Loading data

First thing we are doing to do is to read a CSV file and turn it into a dataframe which we are going to manipulate in the next steps.

### R

```{r}
# We will be loading a CSV file from  RamiKrispin's coronavirus' package.
csv_url = "https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv"

# Read the CSV, convert it into a dataframe and store it in a variable.
r_df <- read.csv(csv_url)

# Explore the first on the dataframe.
head(r_df, 12)
```

### Python

```{python}
import pandas as pd

# We will be loading a CSV file from  RamiKrispin's coronavirus' package.
csv_url = "https://raw.githubusercontent.com/RamiKrispin/coronavirus/master/csv/coronavirus.csv"

# Read the CSV, convert it into a dataframe and store it in a variable.
py_df = pd.read_csv(csv_url)

# Explore the first elements on the dataframe.
py_df.head(12)
```

So far, there are no significant differences between both, but note the following differences:

1.  `R` works with regular **functions**, whereas `python` uses **methods** instead.
2.  In order to work with dataframes in `python`, `pandas` module has to be imported beforehand, whereas it is a base feature from `R`.
3.  Both commands have read the same file but, apparently, they display different data. We will need to explore further the imported data to make sure that both are what we expected and, therefore, the same.

## Exploring a dataframe

In this step we are going to evaluate what kind of object have we created, as well as a very basic data exploration.

### R

```{r}
# Explore what kind of object r_df is.
str(r_df)

# Basic statistics
summary(r_df)

# Explore unique values within a variable.
levels(as.factor(r_df$date))
```

### Python

```{python}
# Explore what kind of entity py_df is.
py_df.info()

# Now, calculate basic statistics for the numeric columns in the DataFrame.
py_df.describe()

# List unique values in the df['date'] column
py_df['date'].unique() # I prefer using this notation to prevent problems with columns with a dot inside.

```

There are no significant differences, nor in the syntax nor in the ouput.

Note:

We prefer to use this notation in order to prevent problems with columns with a dot inside.

## Sorting dataframe

```{r warning=FALSE}
library(tidyverse)

head(arrange(r_df, country))
```

```{python}
py_df.sort_values(['country']).head()

```

## Select and summarise

Let's pretend that we want to have a table displaying the top 10 countries with the most number of confirmed cases until today (`r Sys.Date()`).

### R

```{r message=FALSE, warning=FALSE}
r_df %>% 
  # select(Country.Region, cases, type) %>% 
  filter(type == "confirmed") %>% 
  group_by(country) %>% 
  summarise(total = sum(cases)) %>% 
  arrange(desc(total)) %>% 
  head(5)

# Or, even more succintly:
r_df %>% 
  filter(type == "confirmed") %>% 
  count(country, wt = cases, sort = TRUE, name = "total") %>% 
  head(5)


```

### Python

```{python}
py_df.loc[py_df['type'] == 'confirmed'].groupby('country').agg(
  {'cases':'sum'}
).rename(columns={'cases': 'total'}).sort_values(
  ['total'], ascending = False).head(5)

```

This is something funny. `python` takes pride in stating that is an elegant and easy to read syntax due to its strict indentation syntax. On the other hand, I have met several `python` proponents mocking about `R`'s code to be quite obscure and difficult to memorise. While I often share the same views (especially when dealing with base `R`'s syntax), I particularly find `tidypverse`'s syntax far easier to read and memorise than `pandas`' . While the first makes use of the pipe operator ( `%>%`) to chain commands while preventing typing unnecessary data, the latter requires to concatenate up to six different methods in a single line, which becomes too long to read (and thus, not liked very much by [python's guidelines PEP8](https://www.python.org/dev/peps/pep-0008/#maximum-line-length))

## Joins and calculations

But that's not fair, we are comparing countries with very different number of population! If we are to compare them, we need to use relative values. For example, we would need to create a ranking based on the total number of cases per 1000 habitants.

In order to do so, we will need to do the following steps:

1.  Load a dataframe with population data per each country
2.  Add the population data by join our existing dataframes with the newly created one in the previous step (left join)
3.  Calculate relative number of confirmed cases like this: $confirmed~rel = \frac{confirmed}{population}$

### R

```{r}

# Load population data.
countries19 <- read.csv("data/countries_pop19.csv")

r_df %>% 
  filter(type == "confirmed") %>% 
  count(country, wt = cases, sort = TRUE, name = "confirmed") %>% 
  # Add population column.
  left_join(countries19, by = c("country" = "Location")) %>% 
  # Calculate relative cases.
  mutate(confirmed_rel = confirmed / PopTotal) %>% 
  # Select certain columns only.
  select(country, confirmed, confirmed_rel) %>% 
  # Sort by confirmed_rel on descending order.
  arrange(desc(confirmed_rel)) %>% 
  # Display everything on a nice datatable.
  head(10)
```

### Python

```{python}

# Load population data.
countries19 = pd.read_csv('data/countries_pop19.csv')

py_confirmed_rel = py_df.loc[py_df['type'] == 'confirmed'].groupby('country').agg(
  {'cases':'sum'}
).rename(columns={'cases': 'confirmed'})

# Join population information.
py_confirmed_rel = py_confirmed_rel.join(countries19.set_index('Location'), on = 'country')

# Calculate relative confirmed cases.
py_confirmed_rel = py_confirmed_rel.assign(confirmed_rel = py_confirmed_rel['confirmed']/py_confirmed_rel['PopTotal'])

py_confirmed_rel = py_confirmed_rel[['confirmed', 'confirmed_rel']]

py_confirmed_rel.sort_values(['confirmed_rel'], ascending = False).head(10)
```

## Conclusion

Before concluding, I have to admit that I have been using `tidyverse` for several years, and I am very used to its syntax. Therefore, it is no wonder that I feel much more comfortable with it than with `pandas`' . Being said that, I find the latter to be quite straightforward and relatively easy to use and memorise (I will need to check this post and [this page](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html) for reference). However, I have two main concerns about pandas:

1.  Compared to `R`, which is more succinct, pandas requires to type many times the data frame's name. This makes it more prone-error and slow to type, but also more difficult to read. If you want to avoid typing it as much, you need to chain a number of methods that result in very long lines, which makes it difficult to comment and it is, again, more difficult to read.
2.  I find it somewhat overwhelming that there are many ways to perform same task in `pandas`. I believe Ted Petrou's advice on learning the [minimum sufficient pandas' syntax](https://medium.com/dunder-data/minimally-sufficient-pandas-a8e67f2a2428) is a good advice, as it makes things simpler.
3.  I miss the magritte's pipe operator, but I guess I should change my mindset when using python.

Regarding `reticulate`: I think it is very promising. While `jupyter notebooks` can be used with different kernels such as `Julia`, `python` or `R` (hence its name), there is no way to combine different kernels in the same notebook, at least that I am aware of. This means that only one language per notebook can be used. On the other hand, reticulate allows you to use different languages within the same document (a markdown file, which I prefer it over jupyter notebooks, by the way). Admittedly, I do not know if that is a common scenario, but it has proven to be very useful for a post like this one.

Being said that, I admit that I expected that I could use one variable from `python` and use it in `R`, if that makes any sense at all. However, that's not possible, as both languages are isolated, which I assume is the logical way (I assume is not straightforward at all to convert from one `python` `list` to an `R` `vector`, for example).
